#!/usr/bin/env python
# -*- coding: utf8 -*-
 
# This is a modified version of a script from HA5FTL:
#  http://tlfabian.blogspot.com/2013/10/amateur-ham-radio-analyzing-historical.html

# This simply:
#  1. downloads the parts of the RBN database that have not been previously downloaded, as-is;
#  2. puts the daily data, unchanged, into files with friendly names
 
import os
import time
import urllib2
import datetime
 
base_url = "http://www.reversebeacon.net/raw_data/dl.php?f=" # place at which the data files are stored
zipdata  = "zipfiles"                                        # file containing names of downloaded ZIP files
 
today = datetime.date.today()
delta = datetime.timedelta(1)
 
i = datetime.date(2009, 2, 21)		# start of the RBN data
 
while i <= today:
#while i < datetime.date(2015, 1, 1):
    datestr = "%d%02d%02d" % (i.year, i.month, i.day)
    
    if os.path.isfile(zipdata):
        if datestr in open(zipdata).read():
	    print "%s available" % datestr
            i += delta
            continue
   
    fname = "RBNDATA/%s.zip" % datestr
    url = base_url + datestr
 
    print "Downloading %s..." % url
 
    try:
        content = urllib2.urlopen(url)
        f = open(fname, "w")
        f.write(content.read())
        f.close()
    except urllib2.HTTPError:
        print "Error downloading %s" % url
    except urllib2.URLError:
        print "Error downloading %s" % url
 
    i += delta
    time.sleep(5)					# I suspect that the wait is unnecessary, since the data are probably hosted on a cloud VM; but it does no harm
    